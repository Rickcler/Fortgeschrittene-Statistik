\documentclass{article}

% Math and symbols packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{cancel}
% Formatting and layout
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{enumitem}


% Math and symbols packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{cancel}
% Formatting and layout
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{enumitem}

% Allow align environments to break across pages
\allowdisplaybreaks[4]

% Begin document
\begin{document}
\title{Übung 4 Lösungen}
\author{Victor Minig}
\date{\today}
\maketitle

\section*{1}
\textbf{Gegeben:}\\

Die Dichte einer hypergeometrischen Verteilung: 
\[f(x; M, K, n) = \frac{\binom{K}{x} \binom{M-K}{n-x}}{\binom{M}{n}}I_{\{0,1, \ldots, n\}}(x)\] 

Mit $ M \in \mathbb{N}, ~ K = 0,1, \ldots, M$ und $n = 1,2,\ldots, M$\\\\
\textbf{Gesucht:} \\

Erwartungswert $E(X)$ und Varianz $Var(X)$\\\\
\textbf{Lösung:}\\

Da $X$ diskret ist:
    \begin{align*}
        E(X) &= \sum_{x \in R(X)} x f(x) \\
        &= \sum_{x = 0}^{n} x \frac{\binom{K}{x} \binom{M-K}{n-x}}{\binom{M}{n}} \\
        &=  \\
        Var(X) &= (\sum_{x \in}^{R} x^2 f(x)) - E(X)^2 \\
        &= (\sum_{x = 0}^n x^2 \frac{\binom{K}{x} \binom{M-K}{n-x}}{\binom{M}{n}} ) -  (\frac{nK}{M})^2 \\
        &= (\sum_{x = 1}^n x^2 \frac{\binom{K}{x} \binom{M-K}{n-x}}{\binom{M}{n}} ) -  (\frac{nK}{M})^2 \\
        &= (\sum_{x = 1}^n x^2 \frac{\frac{K}{x}\binom{K-1}{x-1} \binom{M-K}{n-x}}{\binom{M}{n}} ) -  (\frac{nK}{M})^2 \\
        &= (K\sum_{x = 1}^n x \frac{\binom{K-1}{x-1} \binom{M-K}{n-x}}{\binom{M}{n}}) - (\frac{nK}{M})^2 \\
        \text{Setze } y = x-1 \qquad &= (K\sum_{y = 0}^{n-1} (y +1)\frac{\binom{K-1}{y} \binom{M-K}{n-(y+1)}}{\binom{M}{n}}) - (\frac{nK}{M})^2 \\
        &= \left[K \left(\sum_{y = 0}^{n-1}y \frac{\binom{K-1}{y} \binom{M-K}{n-(y+1)}}{\binom{M}{n}} + \frac{\binom{K-1}{y} \binom{M-K}{n-(y+1)}}{\binom{M}{n}} \right)\right] - \left(\frac{nK}{M}\right)^2 \\
        &= \left[K \left(\sum_{y = 1}^{n-1}y \frac{\frac{K-1}{y}\binom{K-2}{y-1} \binom{M-K}{n-(y+1)}}{\binom{M}{n}} + \sum_{y = 0}^{n-1}\frac{\binom{K-1}{y} \binom{M-K}{n-(y+1)}}{\binom{M}{n}} \right)\right] - \left(\frac{nK}{M}\right)^2 \\
        &= \left[K \left((K-1)\sum_{y = 1}^{n-1} \frac{\binom{K-2}{y-1} \binom{M-K}{n-(y+1)}}{\binom{M}{n}} + \sum_{y = 0}^{n-1}\frac{\binom{K-1}{y} \binom{M-K}{n-(y+1)}}{\binom{M}{n}} \right)\right] - \left(\frac{nK}{M}\right)^2\\
        \text{Setze } z = y-1 \qquad&= \left[K \left((K-1)\sum_{z = 0}^{n-2} \frac{\binom{K-2}{z} \binom{M -2 -K + 2}{n-2-(z+ 2) + 2}}{\frac{M}{n} \frac{M-1}{n-1}\binom{M-2}{n-2}} + \sum_{y = 0}^{n-1}\frac{\binom{K-1}{y} \binom{M - 1 - K + 1}{n - 1 - (y+1 ) + 1}}{\frac{M}{n}\binom{M-1}{n-1}} \right)\right] - \left(\frac{nK}{M}\right)^2 \\
        &= \left[K \left((K-1)\frac{n}{M}\frac{n-1}{M-1}\underbrace{\sum_{z = 0}^{n-2} \frac{\binom{K-2}{z} \binom{(M -2) - (K - 2)}{(n-2)- z}}{\binom{M-2}{n-2}}}_{=1, \text{ da } Z \sim Hypergeom(M-2, K-2, n-2)} + \frac{n}{M} \underbrace{\sum_{y = 0}^{n-1}\frac{\binom{K-1}{y} \binom{(M - 1) - (K - 1)}{(n - 1) - y+}}{\binom{M-1}{n-1}}}_{=1, \text{ da } Y \sim Hypergeom(M-1, K-1, n-1)} \right)\right]\\
        &\quad- \left(\frac{nK}{M}\right)^2 \\
        &= K\left((K-1)\frac{n}{M} \frac{n-1}{M-1} + \frac{n}{M} \right) - \left(\frac{nK}{M}\right)^2 \\
        &= (K-1)\frac{nK}{M}\frac{n-1}{M-1} + \frac{nK}{M} - \left(\frac{nK}{M}\right)^2\\
        &= \frac{nK}{M}\left((K-1)\frac{n-1}{M-1}+ 1 - \frac{nK}{M}\right) \\
        &= \frac{nK}{M}\left(\frac{(K-1)(n-1)M}{M(M-1)} + \frac{M(M-1)}{M(M-1)} - \frac{nK(M-1)}{M(M-1)}\right) \\
        &= \frac{nK}{M}\left(\frac{KnM - nM - KM + M + M^2 - M - nKM + nK}{M(M-1)}\right) \\
        &= \frac{nK}{M}\left(\frac{M^2 - nM - KM + nk}{M(M-1)}\right) \\
        &= \frac{nK}{M}\left(\frac{(M-n)(M-k)}{M(M-1)}\right)
    \end{align*}


\section*{2} 
\textbf{Gegeben:}\\

Dichte einer Betaverteilung: 
\[f(x; \alpha, \beta) = \frac{1}{B(\alpha, \beta)}x^{\alpha - 1} (1-x)^{\beta - 1}I_{(0,1)}(x), \qquad \alpha, \beta > 0\]

Wobei B die Betafunktion ist:

\[B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}, \qquad \Gamma(z) = \int_0^{\infty}t^{z-1}e^t ~dt\qquad \text{(Gammafunktion)}\]
\textbf{Gesucht:}\\

Erwartungswert $E(X)$ und Varianz $Var(X)$\\\\
\textbf{Lösung:} \\

\begin{align*}
    E(X) &= \int_{-\infty}^{\infty} x f(x; \alpha, \beta) dx \\
    &= \int_{0}^{1} x \frac{1}{B(\alpha, \beta)}x^{\alpha - 1} (1-x)^{\beta - 1} dx \\
    &= \frac{1}{B(\alpha, \beta)} \int_0^1 x^{\alpha} (1-x)^{\beta -1} dx \\    
    &= \frac{1}{B(\alpha, \beta)} \int_{0}^{1} \frac{B(\alpha +1, \beta)}{B(\alpha +1, \beta)} x^{(\alpha + 1) - 1}(1-x)^{\beta - 1} dx \\
    &= \frac{1}{B(\alpha, \beta)} B(\alpha + 1, \beta) \underbrace{\int_{0}^{1} \frac{1}{B(\alpha + 1, \beta)} x^{(\alpha+1)-1} (1-x)^{\beta -1} dx}_{= 1 \text{ für } X \sim Beta(\alpha + 1, \beta)} \\
    &= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\frac{\Gamma(\alpha + 1)\Gamma(\beta)}{\Gamma(\alpha + 1 + \beta)} \\
    &= \frac{\Gamma(\alpha + \beta) \alpha \Gamma(\alpha)\Gamma(\beta) }{\Gamma(\alpha)\Gamma(\beta)(\alpha+\beta)\Gamma(\alpha + \beta)} \\
    &= \frac{\alpha }{\alpha + \beta} \\
    Var(X) &= \left(\int_{-\infty}^{\infty} x^2 f(x; \alpha, \beta) dx\right) - E(X)^2 \\
    &= \left(\int_{0}^{1} x^2 \frac{1}{B(\alpha, \beta)}x^{\alpha - 1} (1-x)^{\beta - 1} dx\right) - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \left(\frac{1}{B(\alpha, \beta)} \int_{0}^{1} x^{\alpha + 1} (1-x)^{\beta - 1} dx\right) - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \left(\frac{1}{B(\alpha, \beta)} B(\alpha + 2, \beta) \underbrace{\int_{0}^{1} \frac{1}{B(\alpha +2, \beta)} x^{(\alpha + 2)-1} (1-x)^{\beta - 1} dx}_{= 1 \text{ für } X \sim Beta(\alpha + 2, \beta)}\right) - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\frac{\Gamma(\alpha + 2)\Gamma(\beta)}{\Gamma(\alpha + 2 + \beta)} - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \frac{\Gamma(\alpha + \beta) (\alpha + 1 ) \alpha \Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha)\Gamma(\beta)(\alpha+\beta +1) (\alpha + \beta)\Gamma(\alpha + \beta)} - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \frac{\alpha^2 + \alpha}{(\alpha + \beta) (\alpha + \beta + 1)} \\
    &= \frac{\alpha}{\alpha + \beta}\left(\frac{\alpha + 1}{\alpha + \beta + 1} - \frac{\alpha}{\alpha + \beta}\right) \\
    &= \frac{\alpha}{\alpha + \beta} \left(\frac{(\alpha + 1)(\alpha + \beta)- \alpha (\alpha + \beta + 1)}{(\alpha + \beta + 1)(\alpha + \beta)}\right) \\
    &= \frac{\alpha}{\alpha + \beta} \left(\frac{\alpha^2 + \alpha \beta + \alpha + \beta - \alpha^2 - \alpha \beta - \alpha}{(\alpha + \beta + 1)(\alpha + \beta)}\right) \\
    &= \frac{\alpha}{\alpha + \beta}\frac{\beta}{(\alpha + \beta + 1)(\alpha + \beta)} \\
    &= \frac{\alpha \beta}{(\alpha + \beta + 1)(\alpha + \beta)^2}
\end{align*}

\section*{3}
\textbf{Gegeben:} \\

Die Dichte einer Poissonverteilung:
\[f(x;\Theta)= \frac{e^{-\Theta}\Theta^{x}}{x!} I{\{0,1,...\}}(x), \qquad \Theta > 0\] 

Wobei $\Theta$ einer Gammaverteilung mit der Dichte:
\[g(\Theta; r, \lambda) = \frac{\lambda^r}{\Gamma(r)}\Theta^{r-1} e^{-\lambda\Theta}I_{0, \infty}(\Theta), \qquad r, \lambda > 0\]

folgt.\\\\
\textbf{Zu Zeigen:}\\

Die Mischung von Poissonverteilungen 
\[\int_0^{\infty} f(x; \Theta) \cdot g(\Theta; r, \lambda)d\Theta\]

folgt einer negativ Binomialverteilung mit den Parametern $r$ und $p = \frac{\lambda}{\lambda + 1}$ \\ \\
\textbf{Lösung:}

\begin{align*}
    \int_{0}^{\infty} f(x; \Theta) \cdot g(\Theta; r, \lambda) d\Theta &= \int_{0}^{\infty}\frac{e^{-\Theta}\Theta^{x}}{x!} I_{\{0,1,...\}}(x) \cdot \frac{\lambda^r}{\Gamma(r)}\Theta^{r-1} e^{-\lambda\Theta} d\Theta\\
    &= \frac{\lambda^r }{\Gamma(r)x!} I_{\{0,1,...\}}(x) \int_{0}^{\infty} e^{-\Theta}\Theta^{x} \Theta^{r-1}e^{-\lambda \Theta} d \Theta \\
    &= \frac{\lambda^r }{\Gamma(r)x!} I_{\{0,1,...\}}(x) \int_{0}^{\infty} \Theta^{(x+r)-1} e^{-(1+ \lambda)\Theta} d\Theta \\
    &= \frac{\lambda^r}{\Gamma(r)x!} I_{\{0,1,...\}}(x) \int_{0}^{\infty} \frac{\Gamma(r+x)}{(\lambda + 1)^{r+x}}\frac{(\lambda + 1)^{r+x}}{\Gamma(r+x)} \Theta^{(x+r)-1} e^{-(1+ \lambda)\Theta} d\Theta \\
    &= \frac{\lambda^r}{\Gamma(r)x!} I_{\{0,1,...\}}(x) \frac{\Gamma(r+x)}{(\lambda + 1)^{r+x}} \underbrace{\int_{0}^{\infty}\underbrace{\frac{(\lambda + 1)^{r+x}}{\Gamma(r+x)} \Theta^{(x+r)-1} e^{-(1+ \lambda)\Theta}}_{\Theta \sim \Gamma(r+x, \lambda +1)} d \Theta}_{= 1} \\
    &= \frac{\lambda^r \Gamma(r+x)}{\Gamma(r)x! (\lambda+1)^{r+x}} I_{\{0,1,...\}}(x) \\
    &= \frac{\lambda^r \Gamma(r + x)}{\Gamma(r) x! (\lambda + 1)^{r} (\lambda + 1)^{x}} I_{\{0,1,...\}}(x) \\
    &= \frac{\Gamma(r + x)}{\Gamma(r)x!(\lambda+1)^x} \left(\frac{\lambda}{\lambda+1}\right)^r I_{\{0,1,...\}}(x) \\
    &= \frac{\Gamma(r + x)}{\Gamma(r)x!(\lambda+1)^x} \left(\frac{\lambda}{\lambda + 1}\right)^r I_{\{0,1,...\}}(x) \\
\end{align*}

\section*{4}
\subsection*{a)}
\textbf{Gegeben:}\\

Die Dichte der Normalverteilung ist:
\[f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi }\sigma} e^{-(x-\mu)^2/(2\sigma^2)}\]
\textbf{Zu Zeigen:}\\

\[A = \int_{-\infty}^{\infty}f(x; \mu, \sigma)dx = 1\] 
\textbf{Lösung:} \\

Wir zeigen, dass $A^2 = 1$: 
\begin{align*}
    A^2 &= \frac{1}{2\pi \sigma^2} \int_{-\infty}^{\infty} e^{-(x-\mu)^2/(2\sigma^2)} dx \int_{-\infty}^{\infty} e^{-(x-\mu)^2/(2\sigma^2)} dx \\ 
\end{align*}
\subsection*{d)}
\textbf{Zu Zeigen:}\\

Die momenterzeugende Funktion einer standardnormalverteilten ZV ist \[M(t) = e^{\frac{t^2}{2}}\]
\textbf{Lösung:}\\

\begin{align*}
    M_X(t) &= \int_{-\infty}^{\infty} e^{tx}f(x) dx \\
    &= \int_{-\infty}^{\infty} e^{tx} \frac{1}{\sqrt{2\pi} \cdot 1} e^{\left(-\frac{1}{2}\right)\left(\frac{x- 0}{1}\right)^2} dx \\
    &= \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{tx - \frac{x^2}{2}} dx \\
    &= e^{\frac{t^2}{2}} \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}(x-t)^2} dx \\
    &= e^{\frac{t^2}{2}}
\end{align*}
\section*{5}
\textbf{Gegeben:} \\

Bivariate Normalverteilung mit:
\[\mu = \begin{pmatrix}
    \mu_1 \\
    \mu_2
\end{pmatrix} =\begin{pmatrix}
    5 \\
    8
\end{pmatrix} \qquad \text{und} \qquad \Sigma = \begin{pmatrix}
    \Sigma_{11}& \Sigma_{12} \\
    \Sigma_{21}& \Sigma_{22}
\end{pmatrix} = \begin{pmatrix}
    2& -1 \\
    -1& 3
\end{pmatrix}\]
\subsection*{a)}
\textbf{Gesucht:}\\

Regressionsfunktion von $X_1$ auf $X_2$  sowie $E(X_1|x_2 = 9)$
\textbf{Lösung:}\\

Gesucht ist also zunächst:
\begin{align*}
    E(X_1|X_2) &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1}(x_2 - \mu_2) \\
    &= 5 + (-1) \frac{1}{3}(x_2 - 8) \\
    &= 5 - \frac{1}{3} x_2 + \frac{8}{3} \\
    &= \frac{23}{3} - \frac{1}{3} x_2 \\ 
    E(X_1| x_2 = 9) &= \frac{23}{3} - \frac{1}{3} 9  \\
    &=  \frac{14}{3}
\end{align*}
\subsection*{b)}
\textbf{Gesucht:}\\

Bedingte Varianz von $X_1$ gegeben $x_2 = 9$\\\\
\textbf{Lösung:}\\

\begin{align*}
    Var(X_1|x_2 = 9) &= \Sigma_{11} - \Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21} \\
    &= 2 - (-1)\frac{1}{3}(-1)\\
    &= \frac{5}{3}
\end{align*}
\subsection*{c)}
\textbf{Gesucht:}\\

Die Wahrscheinlichkeit $P(x_1 > 5)$ und die bedingte Warscheinlichkeit $P(x_1 > 5| x_2 = 9)$\\\\
\textbf{Lösung:}\\

Da $E(X_1) = 5$ ist und aufgrund der Symmetrie der Normalverteilung um den Ewartungswert gilt $P(x_1 > 5) = \frac{1}{2}$ \\


Wie in $a$ und $b$ gezeigt ist $X_1|x_2 = 9$  verteilt mit $\mathcal{N}(\frac{14}{3}, \frac{5}{3})$. \\

Wir $Z$-standartisieren zunächst (es gilt also $Z \sim \mathcal{N}(0,1)$): \[P(x_1 > 5| x_2 = 9) = P(Z > \frac{5 - \mu_{1|2}}{\sigma_{1|2}}) = P(Z > \frac{5- \frac{14}{3}}{\frac{5}{3}}) = P (Z > 0.2) \] 

\section*{6}
Es folgen einige PDFs und es gilt zu überprüfen, ob es sich um Mitglieder der Exponentialfamilie handelt \\

Eine PDF $f(x;\Theta)$ gilt als Mitglied der Exponentialfamilie wenn:

\[f(x; \Theta) = \begin{cases}
    e^{\sum_{i=1}^{k} c_i(\Theta)g_i(x) + d(\Theta) + z(x)} & \text{for }x\in A\\
    0 &\text{otherwise}
\end{cases}\]

Wobei $x = (x_1, \ldots, x_n)', \Theta = (\Theta_1, \ldots, \Theta_k)'; c_i(\Theta), ~ i = 1, \ldots, k $ und $d(\Theta)$ sind reelwertige Funktionen von $\Theta$ die uanbhängig von $x$  sind  und $g_i(x), i=1, \ldots, k$ und $z(x)$ sind reelwertige Funktionen die nicht abhängig von $\Theta$ sind. $A \in R^n$ ist eine Menge von $n$ Tupeln im $n$-dimensionalen reelen Raum deren Definition unabhäging von $\Theta$ ist  

\subsection*{a)}
\textbf{Gegeben:}\\

Bernoulliverteilung
\[f(x;p) = p^{x}(1-p)^{1-x}I_{\{0,1\}}(x) \qquad p\in[0,1]\]
\textbf{Lösung:}

\begin{align*}
    f(x;p) &= p^{x}(1-p)^{1-x}I_{\{0,1\}}(x) \tag*{$a = e^{\ln(a)}$}\\
    &= e^{\ln(p^{x}(1-p)^{1-x}I_{\{0,1\}}(x))} \tag*{$\ln(a \cdot b) = \ln(a) + \ln(b)$}\\
    &= e^{\ln(p^x) + \ln((1-p)^{1-x}) + \ln(I_{\{0,1\}}(x))} \tag*{$\ln(a^b) = b \cdot \ln(a)$} \\
    &= e^{x\ln(p) + (1-x) \ln(1-p) + \ln(I_{\{0,1\}}(x))} \\
    &= e^{x\ln(p) + \ln(1-p) + x\ln((1-p)^{-1}) + \ln(I_{\{0,1\}}(x))} \\
    &= e^{x(\ln(p) + ln(\frac{1}{1-p})) + \ln(1-p) + \ln(I_{\{0,1\}}(x))} \tag*{$\ln(a)+\ln(b) = \ln(a\cdot b)$}\\
    &= e^{x \ln \left(\frac{p}{1-p}\right) + \ln(1-p) + \ln(I_{\{0,1\}}(x))} \\ \\
    \Longrightarrow ~ &\text{Ist in Exponentialfamilie mit:} \\
    c_i(\Theta) = \ln(\frac{\Theta}{1-\Theta}) &\quad g_i(x) = x \quad d(\Theta) = \ln(1-\Theta) \quad z(x) = \ln(I_{\{0,1\}}(x))
\end{align*}
\subsection*{b)}
\textbf{Gegeben:}\\

Gammaverteilung
\[f(x; \alpha, \beta) = \frac{1}{\beta^{\alpha} \Gamma(\alpha)x^{\alpha-1}} e^{-x/\beta}I_{(0, \infty)}(x), \qquad \alpha, \beta > 0\]
\textbf{Lösung:}
\begin{align*}
    f(x; \alpha, \beta) &= \frac{1}{\beta^{\alpha} \Gamma(\alpha)}x^{\alpha-1} e^{-x/\beta}I_{(0, \infty)}(x) \\ 
    &= e^{\ln(\frac{1}{\beta^{\alpha} \Gamma(\alpha)}x^{\alpha-1})} e^{-x/\beta} e^{ln(I_{(0, \infty)}(x))} \\
    &= e^{\ln(\frac{1}{\beta^{\alpha} \Gamma(\alpha)}x^{\alpha-1})-x/\beta + ln(I_{(0, \infty)}(x))} \\
    &= e^{\ln(\beta^{-\alpha}) + \ln(\Gamma(\alpha)^{-1}) + \ln(x^{\alpha-1}) - \frac{x}{\beta} +ln(I_{(0, \infty)}(x))} \\
    &= e^{-\alpha\ln(\beta) - \ln(\Gamma(\alpha)) + (\alpha -1 )\ln(x)  - \frac{x}{\beta} +ln(I_{(0, \infty)}(x))} \\
    &= e^{(\alpha- 1)\ln(x) - \frac{x}{\beta} - \ln(\Gamma(\alpha)) - \alpha\ln(\beta) + ln(I_{(0, \infty)}(x))} \\ \\
    \Longrightarrow ~ &\text{Ist in Exponentialfamilie mit:} \\
    c_1(\Theta) = \Theta_1 - 1 &\quad g_1(x) = \ln(x) \quad c_2(\Theta) = -\frac{1}{\Theta} \quad g_2(x) = x \\
    d(\Theta) = - \ln(\Gamma(\Theta_1)) &- \Theta_1 \ln(\Theta_2) \quad z(x) = \ln(I_{(0,\infty)}(x))
\end{align*}
\subsection*{c)}
\textbf{Gegeben:}\\

Paretoverteilung
\[f(x, \beta) = \beta x^{-(\beta + 1)} I_{(1, \infty)}(x), \qquad \beta > 0\]
\textbf{Lösung:}
\begin{align*}
    f(x, \beta) &= \beta x^{-(\beta + 1)} I_{(1, \infty)}(x) \\
    &= e^{\ln(\beta x^{-(\beta +1 )})I_{(1, \infty)}(x)}\\
    &= e^{\ln(\beta)+ \ln(x^{-(\beta+1)}) + \ln(I_{(1, \infty)}(x))} \\
    &= e^{(\beta+1)\ln(\frac{1}{x})+ \ln(\beta) +\ln(I_{(1, \infty)}(x))} \\ \\
    \Longrightarrow ~ &\text{Ist in Exponentialfamilie mit:} \\
    c_1(\Theta) = \Theta + 1 \quad & g_1(x) = \ln(\frac{1}{x}) \quad d(\Theta) = \ln(\Theta) \quad z(x) = \ln(I_{(1, \infty)}(x))
\end{align*}
\subsection*{d}
\textbf{Gegeben:}\\

Lognormalverteilung
\[f(x;\mu, \sigma) = \frac{1}{\sqrt{2\pi}\sigma x} e^{-[\ln(x) - \mu]^2/ (2\sigma^2)} I_{(0, \infty)}(x), \qquad \mu \in \mathbb{R}, \sigma > 0.\]
\textbf{Lösung:}

\begin{align*}
    f(x;\mu, \sigma) &= \frac{1}{\sqrt{2\pi}\sigma x} e^{-[\ln(x) - \mu]^2/ (2\sigma^2)} I_{(0, \infty)}(x) \\
    &= e^{\ln(\frac{1}{\sqrt{2 \pi}\sigma x})}e^{-[\ln(x) - \mu]^2/ (2\sigma^2)} e^{\ln(I_{(0, \infty)}(x))} \\
    &= e^{\ln(\frac{1}{\sqrt{2 \pi}\sigma x})-[\ln(x) - \mu]^2/ (2\sigma^2) + \ln(I_{(0, \infty)}(x))} \\
    &= e^{\ln(\frac{1}{\sqrt{2 \pi}\sigma x})- [\ln(x)^2 + \mu^2 - 2\ln(x)\mu]/ (2\sigma^2)+ \ln(I_{(0, \infty)}(x))} \\
    &= e^{\ln(\frac{1}{\sqrt{2 \pi}\sigma})+ \ln(\frac{1}{x})- \frac{\ln(x)^2}{2\sigma^2} - \frac{\mu^2}{2\sigma^2} + \frac{\ln(x)\mu}{\sigma^2} + \ln(I_{(0, \infty)}(x))} \\\\
    \Longrightarrow ~ &\text{Ist in Exponentialfamilie mit:} \\
    c_1(\Theta) = \frac{-1}{2\Theta_2^2} \quad & g_1(x) = \ln(x)^2 \quad c_2 = \frac{\Theta_1}{\Theta_2^2} \quad g_2 = \ln(x) \\
    d(\Theta) = \ln(\frac{1}{\sqrt{2\pi}\Theta_2}) - &\frac{\mu^2}{2\sigma^2}\quad z(x) = \ln(x) + \ln(I_{(0, \infty)}(x))
\end{align*}

\end{document}
